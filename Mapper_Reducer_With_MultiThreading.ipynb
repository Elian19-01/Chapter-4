{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mapper_Reducer_With_MultiThreading.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elian19-01/Chapter-4/blob/main/Mapper_Reducer_With_MultiThreading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y1vVdJ3Ts5G"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB9LNky7QnNN"
      },
      "source": [
        "inputfile = open('Pride_and_Prejudice.txt',\"r\")\n",
        "text = inputfile.read()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuzbj8nARcZW"
      },
      "source": [
        "***Data Cleaning Function***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDn-0fbUUxir"
      },
      "source": [
        "def data_clean(text):\n",
        "  NoNumbers = ''.join([i for i in text if not i.isdigit()]) #Removing numbers \n",
        "  NoNumbers = text.lower()                                  #Making the text to lower case\n",
        "  import re #libreria para manejar textos\n",
        "  onlyText = re.sub(r\"[^a-z\\s]+\",' ',NoNumbers)             #Removing punctuation\n",
        "  finaltext = \"\".join([s for s in onlyText.strip().splitlines(True) if s.strip()]) #Removing the null lines\n",
        "  print(finaltext)\n",
        "  return finaltext"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaZEltG-RY8e"
      },
      "source": [
        "***Split Function***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snUKGq4bsaGY"
      },
      "source": [
        "def splitlines(text,a):\n",
        "  linessplit = text.splitlines() #Splitting the lines into a list\n",
        "  split1 = linessplit[0:a]       #Creating the first split with the first \"a\" number of lines into split 1\n",
        "  split2 = linessplit[a:]       #Creating the second split with the first \"a\" number of lines into split 2\n",
        "  print(str(len(split2)))\n",
        "  return split1,split2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCdqzbevRWQn"
      },
      "source": [
        "***Mapper Function***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnU8GzU5B1xd"
      },
      "source": [
        "def mapper(text,out_queue):\n",
        "  keyval = []\n",
        "  for i in text:\n",
        "    wordssplit = i.split() #split divide las palabras mediante el espacio en blanco\n",
        "    for j in wordssplit:\n",
        "      keyval.append([j,1])      #Appending each word in the line with 1 and storing it in [\"word\",1] format in a nested list\n",
        "  #print(keyval)\n",
        "  print(type(out_queue))\n",
        "  out_queue.put(keyval)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXjUUGQeRNwI"
      },
      "source": [
        "***Sorting Function***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1n2YBEd3LQWV"
      },
      "source": [
        "def sortedlists(list1,list2):\n",
        "  out = list1 + list2             #Appending the two input lists into a single list\n",
        "  out.sort(key= lambda x :x[0])   #Sorting the lists based on the first element of the list which is the \"word\"\n",
        "  return out"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyrRnswARKwa"
      },
      "source": [
        "***Partition Function***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKJD5S4NQ8Sz"
      },
      "source": [
        "def partition(sorted_list) :\n",
        " sort1out = []\n",
        " sort2out = []\n",
        " for i in sorted_list:\n",
        "    if i[0][0] < 'n':             #Partitioning the sorted word list into two separate lists \n",
        "      sort1out.append(i)          #with first list containing words starting with a-m and n-z into second \n",
        "    else : sort2out.append(i)\n",
        " return sort1out,sort2out    "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZO9W2qfaXqp"
      },
      "source": [
        "***Reducer Function***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7tp4nZzci0x"
      },
      "source": [
        "def reducer(part_out1,out_queue) :\n",
        "  sum_reduced = []\n",
        "  count = 1\n",
        "  for i in range(0,len(part_out1)):\n",
        "    if i < len(part_out1)-1:\n",
        "      if part_out1[i] == part_out1[i+1]:\n",
        "       count = count+1                              #Counting the number of words\n",
        "      else : \n",
        "       sum_reduced.append([part_out1[i][0],count])  #Appending the word along with count to sum_reduced list as [\"word\",count]\n",
        "       count = 1 \n",
        "    else: sum_reduced.append(part_out1[i])          #Appending the last word to the output list    \n",
        "  out_queue.put(sum_reduced)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0A44ob5kPr3"
      },
      "source": [
        "***Multi - Threading function:***\n",
        "The user defined function below takes a function and two inputs as arguments. The function is applied on both the inputs simultaneouly and the output is returned by the function.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFa7vWNLkOp8"
      },
      "source": [
        "import threading\n",
        "import queue\n",
        "def multi_thread_function(func,map1_input,map2_input):  #func is the function to be used with two threads taking two inputs map1_input and map2_input\n",
        "  my_queue1 = queue.Queue()  #Using queue to store the values of mapper output to use them in sort function\n",
        "  my_queue2 = queue.Queue()\n",
        "  t1 = threading.Thread(target=func, args=(map1_input,my_queue1)) \n",
        "  t2 = threading.Thread(target=func, args=(map2_input,my_queue2))  \n",
        "  t1.start()                 #Starting the execution of thread1\n",
        "  t2.start()                 #Starting the execution of thread2 to run simultaneously with thread1\n",
        "  t1.join()                  #Waiting for the thread1 to be completely executed\n",
        "  t2.join()                  #Waiting for the thread2 to be completely executed\n",
        "  list1out = my_queue1.get() #Getting the values from the queue into a variable to return its value\n",
        "  list2out = my_queue2.get()\n",
        "  return list1out,list2out"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PwRZCdoxW8w"
      },
      "source": [
        "***Main Function***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT_UyNeIsTMI"
      },
      "source": [
        "def main_function(text):  \n",
        "  cleantext = data_clean(text)\n",
        "  linessplit = splitlines(cleantext,5000)\n",
        "  mapperout = multi_thread_function(mapper,linessplit[0],linessplit[1]) \n",
        "  sortedwords = sortedlists(mapperout[0],mapperout[1])\n",
        "  slicedwords = partition(sortedwords)\n",
        "  reducerout = multi_thread_function(reducer,slicedwords[0],slicedwords[1])\n",
        "  return reducerout[0]+reducerout[1]\n",
        "\n",
        "output = main_function(text)\n",
        "import pandas as pd\n",
        "pd.DataFrame(output).to_csv(\"Output.csv\",index=False,header = [\"Word\",\"Frequency\"]) #Saving file as a .csv file in the current directory"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}